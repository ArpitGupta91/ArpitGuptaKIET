{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **#NLP Phase- 1 Text Processing**"
      ],
      "metadata": {
        "id": "CLBTtLIOHd9B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8710bZo04Znk",
        "outputId": "3404adb3-1f24-45c1-b88b-bcc409f1d6a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original test :  I am feeling very very happy today!!!...\n"
          ]
        }
      ],
      "source": [
        "text=\"I am feeling very very happy today!!!...\"\n",
        "print(\"Original test : \",text);"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1 Convert text into lowercase\n",
        "# becoz happy != Happy\n",
        "# ML will consider them as different\n",
        "text=text.lower()\n",
        "print(\"LowerCase:\",text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DSLNv7X6C90",
        "outputId": "58924c88-fc61-4f5b-92e8-9039635a22f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LowerCase: i am feeling very very happy today!!!...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP-2 : Remove punctuation\n",
        "# we remove eveything except letters and spaces\n",
        "# using re - regular expression - mtlb patterns wagera k liye use hoti hai, jaise hi email ka ek pattern hota hai, password ka ek pattern hota hai\n",
        "import re\n",
        "text=re.sub(r'[^\\w\\s]', '', text)\n",
        "print(\"Wihtout punctuation: \",text);\n",
        "\n",
        "# [^\\w\\s] - remove eveything except letters and spaces"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdLFF-gT6Lk9",
        "outputId": "3e132c2c-56e6-415b-a82c-a00aaa895d4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wihtout punctuation:  i am feeling very very happy today\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3- Tokenization (Split sentence into words)\n",
        "tokens= text.split()\n",
        "print(\"Tokens:\", tokens);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0D42bodg6Lhm",
        "outputId": "2439b1d7-7955-4d4d-9048-7d4a8df03205"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['i', 'am', 'feeling', 'very', 'very', 'happy', 'today']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STep -4 - Remove stop words- i, an, is, are, the, a, an\n",
        "stopwords = [\"i\",\"am\",\"is\",\"the\",\"a\",\"an\",\"very\"]\n",
        "\n",
        "filtered_tokens = []\n",
        "for word in tokens :\n",
        "  if word not in stopwords:\n",
        "    filtered_tokens.append(word)\n",
        "\n",
        "print(\"After removing stopwords :\", filtered_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-uqIWsp6Le9",
        "outputId": "598d3198-bfe1-46bb-87c6-c86ba85ec1be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After removing stopwords : ['feeling', 'happy', 'today']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step - 5 - stemming -remove ing from words like playing\n",
        "def stem(word):\n",
        "  if word.endswith(\"ing\"):\n",
        "    return word[:-3]\n",
        "  return word\n",
        "\n",
        "stemmed_words = []\n",
        "for word in filtered_tokens:\n",
        "  stemmed_words.append(stem(word));\n",
        "\n",
        "print(\"After stemming :\",stemmed_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3DsqFYZ6LcU",
        "outputId": "8d07542a-81c6-46a1-ef07-1d9a9034071d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After stemming : ['feel', 'happy', 'today']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **# NLP - Phase 2 : Words to vector**"
      ],
      "metadata": {
        "id": "8jU1vh-SHzlz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# WHy vectors\n",
        "# Bcoz ML only understands numbers\n",
        "# we must convert words into numeric form\n",
        "\n",
        "# Bag of Words (BoW)"
      ],
      "metadata": {
        "id": "kqAjtNsQ6KnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# will help us to convert text into count\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "metadata": {
        "id": "ILjfLgTrAIo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "    \"i am good\",\n",
        "    \"i am happy\",\n",
        "    \"happy today\",\n",
        "    \"i am sad\"\n",
        "]"
      ],
      "metadata": {
        "id": "TxudMrADAIfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Vectorize\n",
        "vectorizer = CountVectorizer() # creating object\n",
        "X = vectorizer.fit_transform(sentences)\n",
        "#learn vocabulary and covery sentences into number"
      ],
      "metadata": {
        "id": "tPi5KmqHAIbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Vocabulary: \",vectorizer.get_feature_names_out())"
      ],
      "metadata": {
        "id": "wOuoVU0yAvAe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fa5bee6-59d4-4618-91b8-1ab3dae7721c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary:  ['am' 'good' 'happy' 'sad' 'today']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Vectors :\")\n",
        "print(X.toarray())\n"
      ],
      "metadata": {
        "id": "_58xQD4rB6v4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49fe1e28-0589-46d6-d2b9-6c6da2896afb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vectors :\n",
            "[[1 1 0 0 0]\n",
            " [1 0 1 0 0]\n",
            " [0 0 1 0 1]\n",
            " [1 0 0 1 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Here\n",
        "# Each row =sentence\n",
        "# Each column = word\n",
        "# each value =count of word in that sentence"
      ],
      "metadata": {
        "id": "8muicPWvB6sm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences= [\n",
        "    \"i am learning python and python is good\",\n",
        "    \"python is a great programming to learn\",\n",
        "    \"i also love machine leaning with python\"\n",
        "]\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "X=vectorizer.fit_transform(sentences)\n",
        "print(\"Vovabulary: \",vectorizer.get_feature_names_out())\n",
        "print(\"\\nMatrix: \\n\",X.toarray())"
      ],
      "metadata": {
        "id": "jOrmZhIIB6qX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53166085-a8a5-4e23-f9b0-c0391ca0b1b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vovabulary:  ['also' 'am' 'and' 'good' 'great' 'is' 'leaning' 'learn' 'learning' 'love'\n",
            " 'machine' 'programming' 'python' 'to' 'with']\n",
            "\n",
            "Matrix: \n",
            " [[0 1 1 1 0 1 0 0 1 0 0 0 2 0 0]\n",
            " [0 0 0 0 1 1 0 1 0 0 0 1 1 1 0]\n",
            " [1 0 0 0 0 0 1 0 0 1 1 0 1 0 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Here\n",
        "# Each row =sentence\n",
        "# Each column = word\n",
        "# each value =count of word in that sentence"
      ],
      "metadata": {
        "id": "nAXj-48gB6n9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **# TF-IDF- Term Frequency - Inverse Document Frequency bold text**"
      ],
      "metadata": {
        "id": "8Xk3MuAkH8_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bag of words treats all words equally\n",
        "# for example: I am learning python,python and python\n",
        "# it will assing hude weight to python\n"
      ],
      "metadata": {
        "id": "67499VsPB6ic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "71s26t8mB6OG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences= [\n",
        "    \"i am learning python and python is good\",\n",
        "    \"python is a great programming and python is fast\",\n",
        "    \"i also love machine leaning with python\"\n",
        "]"
      ],
      "metadata": {
        "id": "lbEgX9eaIY_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "X=vectorizer.fit_transform(sentences)\n",
        "# Internally it will:\n",
        "# BUild vocabulary\n",
        "# calculate TF - Term Frequency\n",
        "# calculare IDF - Inverse Document Frequency\n",
        "# Multiple tf x idf\n",
        "# Generate matrix"
      ],
      "metadata": {
        "id": "oLHTiaDSIY8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Vocabulary: \",vectorizer.get_feature_names_out())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WM7whx-aIY5r",
        "outputId": "4a4ec491-122e-4f4b-d69f-ed03bc3ef5b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary:  ['also' 'am' 'and' 'fast' 'good' 'great' 'is' 'leaning' 'learning' 'love'\n",
            " 'machine' 'programming' 'python' 'with']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"TF-IDF Matrix: \")\n",
        "print(X.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZXXwrkfIY2o",
        "outputId": "f80fb113-b087-4391-e364-142342fda0e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF Matrix: \n",
            "[[0.         0.42439575 0.32276391 0.         0.42439575 0.\n",
            "  0.32276391 0.         0.42439575 0.         0.         0.\n",
            "  0.50130994 0.        ]\n",
            " [0.         0.         0.28172826 0.3704388  0.         0.3704388\n",
            "  0.56345652 0.         0.         0.         0.         0.3704388\n",
            "  0.43757425 0.        ]\n",
            " [0.43238509 0.         0.         0.         0.         0.\n",
            "  0.         0.43238509 0.         0.43238509 0.43238509 0.\n",
            "  0.2553736  0.43238509]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# \"am learning python and python is good\"\n",
        "# IDF calculation :\n",
        "# log(total documnets/documents containing word)"
      ],
      "metadata": {
        "id": "9OpTm__6LBbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gsy-zgZPLBYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5e6WEnh9LBJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0BwUmk-KLAtR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G-ENo9KjLAp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fMGuzf7pLAa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BZpOgQxyIYio"
      }
    }
  ]
}