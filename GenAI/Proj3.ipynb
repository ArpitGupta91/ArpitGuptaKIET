{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CLBTtLIOHd9B"
   },
   "source": [
    "# **#NLP Phase- 1 Text Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8710bZo04Znk",
    "outputId": "3404adb3-1f24-45c1-b88b-bcc409f1d6a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original test :  I am feeling very very happy today!!!...\n"
     ]
    }
   ],
   "source": [
    "text=\"I am feeling very very happy today!!!...\"\n",
    "print(\"Original test : \",text);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7DSLNv7X6C90",
    "outputId": "58924c88-fc61-4f5b-92e8-9039635a22f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LowerCase: i am feeling very very happy today!!!...\n"
     ]
    }
   ],
   "source": [
    "# Step 1 Convert text into lowercase\n",
    "# becoz happy != Happy\n",
    "# ML will consider them as different\n",
    "text=text.lower()\n",
    "print(\"LowerCase:\",text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gdLFF-gT6Lk9",
    "outputId": "3e132c2c-56e6-415b-a82c-a00aaa895d4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wihtout punctuation:  i am feeling very very happy today\n"
     ]
    }
   ],
   "source": [
    "# STEP-2 : Remove punctuation\n",
    "# we remove eveything except letters and spaces\n",
    "# using re - regular expression - mtlb patterns wagera k liye use hoti hai, jaise hi email ka ek pattern hota hai, password ka ek pattern hota hai\n",
    "import re\n",
    "text=re.sub(r'[^\\w\\s]', '', text)\n",
    "print(\"Wihtout punctuation: \",text);\n",
    "\n",
    "# [^\\w\\s] - remove eveything except letters and spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0D42bodg6Lhm",
    "outputId": "2439b1d7-7955-4d4d-9048-7d4a8df03205"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['i', 'am', 'feeling', 'very', 'very', 'happy', 'today']\n"
     ]
    }
   ],
   "source": [
    "# Step 3- Tokenization (Split sentence into words)\n",
    "tokens= text.split()\n",
    "print(\"Tokens:\", tokens);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f-uqIWsp6Le9",
    "outputId": "598d3198-bfe1-46bb-87c6-c86ba85ec1be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing stopwords : ['feeling', 'happy', 'today']\n"
     ]
    }
   ],
   "source": [
    "# STep -4 - Remove stop words- i, an, is, are, the, a, an\n",
    "stopwords = [\"i\",\"am\",\"is\",\"the\",\"a\",\"an\",\"very\"]\n",
    "\n",
    "filtered_tokens = []\n",
    "for word in tokens :\n",
    "  if word not in stopwords:\n",
    "    filtered_tokens.append(word)\n",
    "\n",
    "print(\"After removing stopwords :\", filtered_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G3DsqFYZ6LcU",
    "outputId": "8d07542a-81c6-46a1-ef07-1d9a9034071d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After stemming : ['feel', 'happy', 'today']\n"
     ]
    }
   ],
   "source": [
    "# Step - 5 - stemming -remove ing from words like playing\n",
    "def stem(word):\n",
    "  if word.endswith(\"ing\"):\n",
    "    return word[:-3]\n",
    "  return word\n",
    "\n",
    "stemmed_words = []\n",
    "for word in filtered_tokens:\n",
    "  stemmed_words.append(stem(word));\n",
    "\n",
    "print(\"After stemming :\",stemmed_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8jU1vh-SHzlz"
   },
   "source": [
    "# **# NLP - Phase 2 : Words to vector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "kqAjtNsQ6KnC"
   },
   "outputs": [],
   "source": [
    "# WHy vectors\n",
    "# Bcoz ML only understands numbers\n",
    "# we must convert words into numeric form\n",
    "\n",
    "# Bag of Words (BoW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ILjfLgTrAIo6"
   },
   "outputs": [],
   "source": [
    "# will help us to convert text into count\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "TxudMrADAIfD"
   },
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"i am good\",\n",
    "    \"i am happy\",\n",
    "    \"happy today\",\n",
    "    \"i am sad\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "tPi5KmqHAIbh"
   },
   "outputs": [],
   "source": [
    "#Vectorize\n",
    "vectorizer = CountVectorizer() # creating object\n",
    "X = vectorizer.fit_transform(sentences)\n",
    "#learn vocabulary and covery sentences into number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wOuoVU0yAvAe",
    "outputId": "2fa5bee6-59d4-4618-91b8-1ab3dae7721c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary:  ['am' 'good' 'happy' 'sad' 'today']\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary: \",vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_58xQD4rB6v4",
    "outputId": "49fe1e28-0589-46d6-d2b9-6c6da2896afb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectors :\n",
      "[[1 1 0 0 0]\n",
      " [1 0 1 0 0]\n",
      " [0 0 1 0 1]\n",
      " [1 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Vectors :\")\n",
    "print(X.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "8muicPWvB6sm"
   },
   "outputs": [],
   "source": [
    "# Here\n",
    "# Each row =sentence\n",
    "# Each column = word\n",
    "# each value =count of word in that sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jOrmZhIIB6qX",
    "outputId": "53166085-a8a5-4e23-f9b0-c0391ca0b1b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vovabulary:  ['also' 'am' 'and' 'good' 'great' 'is' 'leaning' 'learn' 'learning' 'love'\n",
      " 'machine' 'programming' 'python' 'to' 'with']\n",
      "\n",
      "Matrix: \n",
      " [[0 1 1 1 0 1 0 0 1 0 0 0 2 0 0]\n",
      " [0 0 0 0 1 1 0 1 0 0 0 1 1 1 0]\n",
      " [1 0 0 0 0 0 1 0 0 1 1 0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "sentences= [\n",
    "    \"i am learning python and python is good\",\n",
    "    \"python is a great programming to learn\",\n",
    "    \"i also love machine leaning with python\"\n",
    "]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X=vectorizer.fit_transform(sentences)\n",
    "print(\"Vovabulary: \",vectorizer.get_feature_names_out())\n",
    "print(\"\\nMatrix: \\n\",X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "nAXj-48gB6n9"
   },
   "outputs": [],
   "source": [
    "# Here\n",
    "# Each row =sentence\n",
    "# Each column = word\n",
    "# each value =count of word in that sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Xk3MuAkH8_n"
   },
   "source": [
    "# **# TF-IDF- Term Frequency - Inverse Document Frequency bold text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "67499VsPB6ic"
   },
   "outputs": [],
   "source": [
    "# Bag of words treats all words equally\n",
    "# for example: I am learning python,python and python\n",
    "# it will assing hude weight to python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "71s26t8mB6OG"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "lbEgX9eaIY_6"
   },
   "outputs": [],
   "source": [
    "sentences= [\n",
    "    \"i am learning python and python is good\",\n",
    "    \"python is a great programming and python is fast\",\n",
    "    \"i also love machine leaning with python\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "oLHTiaDSIY8e"
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X=vectorizer.fit_transform(sentences)\n",
    "# Internally it will:\n",
    "# BUild vocabulary\n",
    "# calculate TF - Term Frequency\n",
    "# calculare IDF - Inverse Document Frequency\n",
    "# Multiple tf x idf\n",
    "# Generate matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WM7whx-aIY5r",
    "outputId": "4a4ec491-122e-4f4b-d69f-ed03bc3ef5b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary:  ['also' 'am' 'and' 'fast' 'good' 'great' 'is' 'leaning' 'learning' 'love'\n",
      " 'machine' 'programming' 'python' 'with']\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary: \",vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ZXXwrkfIY2o",
    "outputId": "f80fb113-b087-4391-e364-142342fda0e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Matrix: \n",
      "[[0.         0.42439575 0.32276391 0.         0.42439575 0.\n",
      "  0.32276391 0.         0.42439575 0.         0.         0.\n",
      "  0.50130994 0.        ]\n",
      " [0.         0.         0.28172826 0.3704388  0.         0.3704388\n",
      "  0.56345652 0.         0.         0.         0.         0.3704388\n",
      "  0.43757425 0.        ]\n",
      " [0.43238509 0.         0.         0.         0.         0.\n",
      "  0.         0.43238509 0.         0.43238509 0.43238509 0.\n",
      "  0.2553736  0.43238509]]\n"
     ]
    }
   ],
   "source": [
    "print(\"TF-IDF Matrix: \")\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "9OpTm__6LBbq"
   },
   "outputs": [],
   "source": [
    "# \"am learning python and python is good\"\n",
    "# IDF calculation :\n",
    "# log(total documnets/documents containing word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gsy-zgZPLBYI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5e6WEnh9LBJj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0BwUmk-KLAtR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G-ENo9KjLAp1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fMGuzf7pLAa-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BZpOgQxyIYio"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
